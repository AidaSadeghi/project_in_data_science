{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) \n",
      "[Clang 13.0.1 ]\n"
     ]
    }
   ],
   "source": [
    "# Check python version.\n",
    "# This code should run for python version >=3.6\n",
    "\n",
    "print(\"python\", sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles = pd.read_csv(\"vehicles.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = vehicles.copy()\n",
    "reduced_df = reduced_df[reduced_df['price'] > 0]\n",
    "reduced_df = reduced_df[reduced_df['price'].notna()]\n",
    "reduced_df = reduced_df[reduced_df['price'] < 1000000]\n",
    "reduced_df = reduced_df[~((reduced_df.manufacturer.isnull()) & (reduced_df.manufacturer.isnull()))]\n",
    "reduced_df = reduced_df.drop(columns=[\n",
    "    'county', \n",
    "    'id', \n",
    "    'region_url', \n",
    "    'url', \n",
    "    'image_url',\n",
    "    'VIN'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(reduced_df, test_size=0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df_in):\n",
    "    \n",
    "    df = df_in.copy()\n",
    "    \n",
    "    N = 50\n",
    "    topN_models = df.model.value_counts().head(N).index.to_numpy()\n",
    "    df.loc[~df['model'].isin(topN_models),'model'] = 'unknown'\n",
    "    top_models = list(train_set.model.unique())\n",
    "    \n",
    "    df = df.drop(columns=[\n",
    "        'size', \n",
    "        'drive', \n",
    "        'lat', \n",
    "        'long', \n",
    "        'posting_date', \n",
    "        'paint_color', \n",
    "        'description',\n",
    "        'state',\n",
    "        'region'\n",
    "    ])\n",
    "    \n",
    "    df.loc[~df['model'].isin(top_models),'model'] = 'unknown'\n",
    "    \n",
    "    df = df.dropna(subset=['year', 'odometer','manufacturer'])\n",
    "    df['type'].fillna('unknown',inplace=True)\n",
    "    df['title_status'].fillna('clean', inplace=True)\n",
    "    df['fuel'].fillna('gas', inplace=True)\n",
    "    df['cylinders'].fillna('unknown', inplace=True)\n",
    "    df['transmission'].fillna('automatic', inplace=True)\n",
    "    df['condition'].fillna('good', inplace=True)\n",
    "    \n",
    "    \n",
    "    X = df.drop('price', axis=1)\n",
    "    y = df['price'].copy()\n",
    "    \n",
    "    return(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "X, y = preprocess(train_set)\n",
    "\n",
    "num_attribs = list(X.select_dtypes('number'))\n",
    "cat_attribs = list(X.select_dtypes('object'))\n",
    "\n",
    "\n",
    "pipeline = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_attribs),\n",
    "    ('cat', OneHotEncoder(), cat_attribs)\n",
    "])\n",
    "\n",
    "X_prepared = pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error  138113434.15391302\n",
      "Root mean squared error  11752.167210940841\n",
      "Mean absolute error  7609.628529974464\n",
      "Mean absolute percentage error 87.6946042693848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# initializing the model\n",
    "lin_model = LinearRegression()\n",
    "# fitting on training data\n",
    "lin_model.fit(X_prepared, y)\n",
    "# getting the predictions for the y_train\n",
    "y_train_pred = lin_model.predict(X_prepared)\n",
    "\n",
    "mse = mean_squared_error(y, y_train_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y, y_train_pred)\n",
    "mape = mean_absolute_percentage_error(y, y_train_pred)\n",
    "\n",
    "print(\"Mean squared error \", mse)\n",
    "print(\"Root mean squared error \", rmse)\n",
    "print(\"Mean absolute error \", mae)\n",
    "print(\"Mean absolute percentage error\", mape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Train a `sklearn.tree.DecisionTreeRegressor` model. First train it on the full training set and then try 3-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "dt_model = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "dt_model.fit(X_prepared, y)\n",
    "y_train_pred = dt_model.predict(X_prepared)\n",
    "print(\"Mean squared error \", mean_squared_error(y, y_train_pred))\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_validate(dt_model, X_prepared, y, cv=3, scoring=\"neg_mean_squared_error\")\n",
    "cross_val_score(dt_model, X_prepared, y, cv=3, scoring=\"neg_mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8007140488524288\n",
      "CPU times: user 28 µs, sys: 14 µs, total: 42 µs\n",
      "Wall time: 46.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "params = {'n_estimators':[5, 10], 'max_features': [\"sqrt\", \"log2\"]}\n",
    "grid_search_cv = GridSearchCV(RandomForestRegressor(), params, verbose=1, cv=3)\n",
    "\n",
    "grid_search_cv.fit(X_prepared, y)\n",
    "print(grid_search_cv.best_estimator_)\n",
    "print(grid_search_cv.best_score_)\n",
    "# output\n",
    "# Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
    "# CPU times: user 12min 12s, sys: 1.81 s, total: 12min 14s\n",
    "# Wall time: 12min 14s\n",
    "# GridSearchCV(cv=3, estimator=RandomForestRegressor(),\n",
    "#              param_grid={'max_features': ['sqrt', 'log2'],\n",
    "#                          'n_estimators': [5, 10]},\n",
    "#              verbose=1)\n",
    "# Best estimator: RandomForestRegressor(max_features='sqrt', n_estimators=10)\n",
    "# Best score: 0.8007140488524288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7957024744754345"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "params = {'n_estimators': [5, 10], 'max_features': [\"sqrt\", \"log2\"]}\n",
    "rand_search_cv = RandomizedSearchCV(RandomForestRegressor(), params, verbose=1, cv=3)\n",
    "rand_search_cv.fit(X_prepared, y)\n",
    "rand_search_cv.best_estimator_\n",
    "rand_search_cv.best_score_\n",
    "# output\n",
    "# Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
    "# RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(),\n",
    "#                    param_distributions={'max_features': ['sqrt', 'log2'],\n",
    "#                                         'n_estimators': [5, 10]},\n",
    "#                    verbose=1)\n",
    "# Best estimator: RandomForestRegressor(max_features='log2', n_estimators=10)\n",
    "# Best score: 0.7957024744754345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error for poly regression 79824293.25779378\n",
      "Root mean squared error  8934.444205309796\n",
      "Mean absolute error  5000.970054046256\n",
      "Mean absolute percentage error 67.56168172762246\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/.venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(X_prepared)\n",
    "\n",
    "lin_model = LinearRegression()\n",
    "lin_model.fit(X_poly, y)\n",
    "y_train_pred = lin_model.predict(X_poly)\n",
    "\n",
    "mse = mean_squared_error(y, y_train_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y, y_train_pred)\n",
    "mape = mean_absolute_percentage_error(y, y_train_pred)\n",
    "\n",
    "print(\"Mean squared error for poly regression\", mse)\n",
    "print(\"Root mean squared error \", rmse)\n",
    "print(\"Mean absolute error \", mae)\n",
    "print(\"Mean absolute percentage error\", mape)\n",
    "\n",
    "# Support vector regressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svm_reg = SVC()\n",
    "\n",
    "params = {'kernel':[\"linear\",\"poly\",\"rbf\"]}\n",
    "grid_search_cv = GridSearchCV(SVC(), params, verbose=1, cv=3)\n",
    "\n",
    "grid_search_cv.fit(X_prepared, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "msrp_df = pd.read_csv(\"msrp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in msrp_df.columns:\n",
    "    new_col = '_'.join(col.lower().split(' '))\n",
    "    msrp_df.rename({col: new_col}, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "msrp_df['is_luxury'] = msrp_df.market_category.str.contains('Luxury')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "msrp_df = msrp_df.drop(columns=['model','market_category', 'make', 'msrp', 'popularity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "msrp_train_set, msrp_test_set = train_test_split(\n",
    "    msrp_df.dropna(subset=['is_luxury']), \n",
    "    test_size=0.1, \n",
    "    random_state=123)\n",
    "msrp_train_df = msrp_train_set.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Make sure you understand what the above code is doing and verify that `msrp_train_df` has the features we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Get familiar with the training data, assuming now that `is_luxury` is our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2876     True\n",
      "4564    False\n",
      "7937     True\n",
      "3373    False\n",
      "8774    False\n",
      "Name: is_luxury, dtype: object\n",
      "                      year  engine_hp  engine_cylinders  number_of_doors  \\\n",
      "year              1.000000   0.243878         -0.052106         0.178450   \n",
      "engine_hp         0.243878   1.000000          0.812305        -0.200619   \n",
      "engine_cylinders -0.052106   0.812305          1.000000        -0.182974   \n",
      "number_of_doors   0.178450  -0.200619         -0.182974         1.000000   \n",
      "highway_mpg       0.198245  -0.456802         -0.603422         0.103950   \n",
      "city_mpg          0.157091  -0.482778         -0.591754         0.125558   \n",
      "\n",
      "                  highway_mpg  city_mpg  \n",
      "year                 0.198245  0.157091  \n",
      "engine_hp           -0.456802 -0.482778  \n",
      "engine_cylinders    -0.603422 -0.591754  \n",
      "number_of_doors      0.103950  0.125558  \n",
      "highway_mpg          1.000000  0.876425  \n",
      "city_mpg             0.876425  1.000000  \n",
      "==============================\n",
      "year                 0.000000\n",
      "engine_fuel_type     0.000000\n",
      "engine_hp            0.007207\n",
      "engine_cylinders     0.003671\n",
      "transmission_type    0.000000\n",
      "driven_wheels        0.000000\n",
      "number_of_doors      0.000816\n",
      "vehicle_size         0.000000\n",
      "vehicle_style        0.000000\n",
      "highway_mpg          0.000000\n",
      "city_mpg             0.000000\n",
      "is_luxury            0.000000\n",
      "dtype: float64\n",
      "200.0    251\n",
      "210.0    233\n",
      "240.0    231\n",
      "285.0    196\n",
      "300.0    157\n",
      "        ... \n",
      "480.0      1\n",
      "535.0      1\n",
      "622.0      1\n",
      "592.0      1\n",
      "298.0      1\n",
      "Name: engine_hp, Length: 326, dtype: int64\n",
      "4.0     2806\n",
      "6.0     2635\n",
      "8.0     1400\n",
      "12.0     207\n",
      "5.0      149\n",
      "10.0      61\n",
      "0.0       47\n",
      "3.0       19\n",
      "16.0       3\n",
      "Name: engine_cylinders, dtype: int64\n",
      "4.0    5125\n",
      "2.0    2056\n",
      "3.0     167\n",
      "Name: number_of_doors, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kz/7d2p7tls4jbgj17nt6ghbbgw0000gn/T/ipykernel_8996/1459258545.py:6: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  print(msrp_train_df.corr())\n"
     ]
    }
   ],
   "source": [
    "print(msrp_train_df['is_luxury'].head(5))\n",
    "# print(msrp_train_set.columns)\n",
    "# print(msrp_train_set.info())\n",
    "# print(msrp_train_set.describe())\n",
    "\n",
    "print(msrp_train_df.corr())\n",
    "\n",
    "print(\"=\"*30)\n",
    "N = len(msrp_train_df.index)\n",
    "print(msrp_train_df.isnull().sum()/N)\n",
    "\n",
    "# columns with null values:\n",
    "# year                 0.000000\n",
    "# engine_fuel_type     0.000000\n",
    "# engine_hp            0.007207\n",
    "# engine_cylinders     0.003671\n",
    "# transmission_type    0.000000\n",
    "# driven_wheels        0.000000\n",
    "# number_of_doors      0.000816\n",
    "# vehicle_size         0.000000\n",
    "# vehicle_style        0.000000\n",
    "# highway_mpg          0.000000\n",
    "# city_mpg             0.000000\n",
    "# is_luxury            0.000000\n",
    "\n",
    "cols_w_null = ['engine_hp','engine_cylinders','number_of_doors']\n",
    "# printing most common values\n",
    "for col in cols_w_null:\n",
    "    print(msrp_train_df[col].value_counts())\n",
    "\n",
    "# engine hp is a number so we will replace with the average\n",
    "# engine_cylinders has the numbe 4.0 as the most common\n",
    "# number of doors has the most common as 4.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Prepare the MSRP training data for machine learning algorithms, treating `is_luxury` as the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def prepare_data(X):\n",
    "\n",
    "    # replace null values or drop\n",
    "    \n",
    "    X['engine_hp'].fillna(msrp_train_df['engine_hp'].mean(), inplace=True)\n",
    "    X['engine_cylinders'].fillna(4.0, inplace=True)\n",
    "    X['number_of_doors'].fillna(4.0, inplace=True)\n",
    "\n",
    "    X['is_luxury'] = X['is_luxury'].astype(int)\n",
    "    y_ = X['is_luxury'].copy()\n",
    "    X_unprepared = X.drop('is_luxury', axis=1)\n",
    "    \n",
    "    \n",
    "\n",
    "    num_attribs = list(X_unprepared.select_dtypes('number'))\n",
    "    cat_attribs = list(X_unprepared.select_dtypes('object'))\n",
    "\n",
    "    print(num_attribs)\n",
    "    print()\n",
    "    print(cat_attribs)\n",
    "\n",
    "    pipeline = ColumnTransformer([\n",
    "    (\"num\", Pipeline([\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ]), num_attribs),\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs )\n",
    "    ])\n",
    "\n",
    "    X_ = pipeline.fit_transform(X_unprepared)\n",
    "    \n",
    "    \n",
    "\n",
    "    return (X_,y_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['year', 'engine_hp', 'engine_cylinders', 'number_of_doors', 'highway_mpg', 'city_mpg']\n",
      "\n",
      "['engine_fuel_type', 'transmission_type', 'driven_wheels', 'vehicle_size', 'vehicle_style']\n",
      "MODEL:  LogisticRegression\n",
      " * accuracy  0.8093554528147947\n",
      " * precision_score  0.7737122557726466\n",
      " * recall_score  0.7400611620795107\n",
      " * f1_score  0.756512678013199\n",
      " * confusion_matrix \n",
      "[[3774  637]\n",
      " [ 765 2178]]\n",
      "MODEL:  DecisionTreeClassifier\n",
      " * accuracy  0.9959205874354093\n",
      " * precision_score  0.9955767267778156\n",
      " * recall_score  0.9942235813795447\n",
      " * f1_score  0.9948996939816389\n",
      " * confusion_matrix \n",
      "[[4398   13]\n",
      " [  17 2926]]\n",
      "MODEL:  SGDClassifier\n",
      " * accuracy  0.8079956486265978\n",
      " * precision_score  0.7670038367631671\n",
      " * recall_score  0.7471967380224261\n",
      " * f1_score  0.7569707401032704\n",
      " * confusion_matrix \n",
      "[[3743  668]\n",
      " [ 744 2199]]\n",
      "MODEL:  SVM\n",
      " * accuracy  0.8111231982594507\n",
      " * precision_score  0.7965648854961832\n",
      " * recall_score  0.709140332993544\n",
      " * f1_score  0.750314578464857\n",
      " * confusion_matrix \n",
      "[[3878  533]\n",
      " [ 856 2087]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve\n",
    "models = []\n",
    "\n",
    "X_train, y_train= prepare_data(msrp_train_df)\n",
    "\n",
    "\n",
    "l_reg = LogisticRegression(solver=\"lbfgs\", max_iter=1000, random_state=123).fit(X_train, y_train)\n",
    "models.append((\"LogisticRegression\",l_reg, l_reg.predict(X_train)))\n",
    "tree_clf = DecisionTreeClassifier(random_state=123).fit(X_train, y_train)\n",
    "models.append((\"DecisionTreeClassifier\",tree_clf, tree_clf.predict(X_train)))\n",
    "sgd_clf = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42).fit(X_train, y_train)\n",
    "models.append((\"SGDClassifier\",sgd_clf, sgd_clf.predict(X_train)))\n",
    "svm_clf = SVC(kernel=\"linear\", C=5, random_state=123).fit(X_train, y_train)\n",
    "models.append((\"SVM\",svm_clf, svm_clf.predict(X_train)))\n",
    "\n",
    "for model in models:\n",
    "    print(\"MODEL: \", model[0])\n",
    "    print(\" * accuracy \",accuracy_score(y_train, model[2]))\n",
    "    print(\" * precision_score \",precision_score(y_train, model[2]))\n",
    "    print(\" * recall_score \",recall_score(y_train, model[2]))\n",
    "    print(\" * f1_score \",f1_score(y_train, model[2]))\n",
    "    print(\" * confusion_matrix \")\n",
    "    print(confusion_matrix(y_train, model[2]))\n",
    "\n",
    "# best from output:\n",
    "# MODEL:  DecisionTreeClassifier\n",
    "#  * accuracy  0.9959205874354093\n",
    "#  * precision_score  0.9955767267778156\n",
    "#  * recall_score  0.9942235813795447\n",
    "#  * f1_score  0.9948996939816389\n",
    "#  * confusion_matrix \n",
    "# [[4398   13]\n",
    "#  [  17 2926]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['year', 'engine_hp', 'engine_cylinders', 'number_of_doors', 'highway_mpg', 'city_mpg']\n",
      "\n",
      "['engine_fuel_type', 'transmission_type', 'driven_wheels', 'vehicle_size', 'vehicle_style']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 40 features, but DecisionTreeClassifier is expecting 43 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kz/7d2p7tls4jbgj17nt6ghbbgw0000gn/T/ipykernel_8996/3699253732.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# it was complaining about being trained on 43 features but receiving only 40 from the test set,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# I checked the columns and the pre-processing and nothing was out of the ordinary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0my_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validating on test data with Decision Tree Classifier\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/.venv/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[1;32m    466\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/.venv/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;34m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             if issparse(X) and (\n\u001b[1;32m    435\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/.venv/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/.venv/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    401\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 40 features, but DecisionTreeClassifier is expecting 43 features as input."
     ]
    }
   ],
   "source": [
    "msrp_test_df = msrp_test_set.copy()\n",
    "\n",
    "X_test, y_test = prepare_data(msrp_test_df)\n",
    "\n",
    "\n",
    "\n",
    "y_test_pred = tree_clf.predict(X_test)\n",
    "\n",
    "print(\"Validating on test data with Decision Tree Classifier\")\n",
    "print(\" * accuracy \",accuracy_score(y_test, y_test_pred))\n",
    "print(\" * precision_score \",precision_score(y_test, y_test_pred))\n",
    "print(\" * recall_score \",recall_score(y_test, y_test_pred))\n",
    "print(\" * f1_score \",f1_score(y_test, y_test_pred))\n",
    "print(\" * confusion_matrix \")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a1d81e0ab65a2d871dd04cd5480301015f0912bc0455ad9e82832e105402504a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
